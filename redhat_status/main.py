#!/usr/bin/env python3
"""
Red Hat Status Checker - Main Entry Point

This is the main entry point for the modular Red Hat Status Checker.
It provides all the functionality of the original script but with
improved organization and maintainability.

Usage:
    python3 main.py [options]
    
For backward compatibility, this maintains the same CLI interface
as the original redhat_summary_status.py script.

Author: Red Hat Status Checker v3.1.0 - Modular Edition
"""

import sys
import os
import argparse
from typing import Dict, Any
import logging
import json
import time
from datetime import datetime
from pathlib import Path

# Ensure the project root is in the Python path for package imports
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

# Import our modular components
from redhat_status.config.config_manager import get_config
from redhat_status.core.api_client import get_api_client, fetch_status_data
from redhat_status.core.data_models import PerformanceMetrics, AlertSeverity
from redhat_status.utils.decorators import performance_monitor, Timer
from redhat_status.presentation.presenter import Presenter

# Initialize enterprise features if enabled
try:
    from redhat_status.analytics import get_analytics
    from redhat_status.database import get_database_manager
    from redhat_status.notifications import get_notification_manager
    ENTERPRISE_FEATURES = True
except ImportError:
    ENTERPRISE_FEATURES = False


class RedHatStatusChecker:
    """Main application class for Red Hat Status Checker"""
    
    def __init__(self, exporter_module=None):
        """
        Initialize the application.

        Args:
            exporter_module: An optional module to handle metrics exporting (e.g., Prometheus).
        """
        self.config = get_config()
        self.api_client = get_api_client()
        self.presenter = Presenter()
        self.performance = PerformanceMetrics(start_time=datetime.now())
        self.exporter_module = exporter_module
        
        # Initialize enterprise features if available
        self.analytics = None
        self.db_manager = None
        self.notification_manager = None
        
        if ENTERPRISE_FEATURES:
            try:
                # Initialize AI analytics if enabled
                if self._get_config_value('ai_analytics', 'enabled', False):
                    self.analytics = get_analytics()
                    logging.info("AI Analytics enabled")
                
                # Initialize database if enabled
                if self._get_config_value('database', 'enabled', False):
                    self.db_manager = get_database_manager()
                    logging.info("Database management enabled")
                
                # Initialize notifications if enabled
                email_config = self._get_config_value('notifications', 'email', {})
                webhook_config = self._get_config_value('notifications', 'webhooks', {})
                if (email_config.get('enabled', False) or webhook_config.get('enabled', False)):
                    self.notification_manager = get_notification_manager()
                    logging.info("Notification system enabled")
                else:
                    logging.info("Notifications disabled in configuration")
                
            except Exception as e:
                logging.warning(f"Failed to initialize enterprise features: {e}")
                # Don't modify global variable here, just set instance variables
                self.analytics = None
                self.db_manager = None
                self.notification_manager = None

    def _get_config_value(self, section: str, key: str, default: Any = None) -> Any:
        """Helper to get configuration values from either dict or ConfigManager"""
        try:
            if hasattr(self.config, 'get') and hasattr(self.config.get, '__code__') and self.config.get.__code__.co_argcount > 2:
                # It's a ConfigManager with get(section, key, default) method
                return self.config.get(section, key, default)
            elif hasattr(self.config, 'get'):
                # It's likely a mock or object with get method, try calling it directly
                try:
                    return self.config.get(section, key, default)
                except TypeError:
                    # If the get method doesn't accept 3 args, it might be a dict-like get
                    return self.config.get(section, {}).get(key, default)
            else:
                # It's a dictionary, use nested key access
                if isinstance(self.config, dict):
                    return self.config.get(section, {}).get(key, default)
                return default
        except Exception:
            # Fallback to default if anything goes wrong
            return default

    @performance_monitor
    def quick_status_check(self, quiet_mode: bool = False) -> None:
        """Perform quick status check with global availability percentage"""
        try:
            response = fetch_status_data()
            if not response.success:
                self.presenter.present_error(f"Failed to fetch status data: {response.error_message}")
                return

            data = response.data
            if not data:
                self.presenter.present_error("No data received")
                return

            health_metrics = self.api_client.get_service_health_metrics(data)
            
            self.presenter.present_quick_status(health_metrics, data.get('_metadata', {}).get('cached', False), quiet_mode)

            # Update metrics if exporter is enabled
            if self.exporter_module:
                from redhat_status.core.cache_manager import get_cache_manager
                cache_info = get_cache_manager().get_cache_info()
                # Ensure response_time exists on the response object, default to a value if not.
                response_time = getattr(response, 'response_time', 0.0)
                perf_data = {'cache_info': cache_info.__dict__, 'api_response_time': response_time}
                self.exporter_module.update_metrics(health_metrics, data.get('components', []), perf_data)

            # Save metrics if enterprise features enabled
            if self.db_manager:
                try:
                    self.db_manager.save_service_snapshot(health_metrics, data.get('components', []))
                except Exception as e:
                    logging.error(f"Failed to save metrics: {e}")
            
        except Exception as e:
            logging.error(f"Quick status check failed: {e}")
            self.presenter.present_error(f"Error during status check: {e}")
    
    def _present_quick_status(self, health_metrics: Dict[str, Any], cached: bool = False, quiet_mode: bool = False) -> None:
        """Present quick status results (internal method for testing)
        
        Args:
            health_metrics: Health metrics dictionary
            cached: Whether data was cached
            quiet_mode: Whether to use quiet output mode
        """
        self.presenter.present_quick_status(health_metrics, cached, quiet_mode)
    
    def simple_check_only(self) -> None:
        """Check main services only"""
        try:
            response = fetch_status_data()
            
            if not response.success:
                self.presenter.present_error(f"Failed to fetch data: {response.error_message}")
                return
            
            data = response.data
            components = data.get('components', [])
            
            self.presenter.present_simple_check(components)
                
        except Exception as e:
            logging.error(f"Simple check failed: {e}")
            self.presenter.present_error(f"Error during simple check: {e}")
    
    def full_check_with_services(self) -> None:
        """Complete service hierarchy check"""
        try:
            response = fetch_status_data()
            
            if not response.success:
                self.presenter.present_error(f"Failed to fetch data: {response.error_message}")
                return
            
            data = response.data
            components = data.get('components', [])
            
            self.presenter.present_full_check(components)
                    
        except Exception as e:
            logging.error(f"Full check failed: {e}")
            self.presenter.present_error(f"Error during full check: {e}")
    
    def export_to_file(self, output_dir: str = ".") -> None:
        """Export data to files"""
        self.presenter.present_message("\nüíæ DATA EXPORT")
        self.presenter.present_message("-" * 40)
        
        try:
            response = fetch_status_data()
            
            if not response.success:
                self.presenter.present_error(f"Failed to fetch data for export: {response.error_message}")
                return
            
            data = response.data
            
            # Ensure output directory exists
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime(self._get_config_value('output', 'timestamp_format', '%Y%m%d_%H%M%S'))
            filename = os.path.join(output_dir, f"redhat_status_{timestamp}.json")
            
            # Export JSON data
            import json
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # Get file size
            file_size = os.path.getsize(filename)
            file_size_kb = file_size / 1024
            
            self.presenter.present_message(f"‚úÖ Data exported to: {filename}")
            self.presenter.present_message(f"üìä File size: {file_size_kb:.1f} KB ({file_size} bytes)")
            self.presenter.present_message(f"üìÖ Export time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Create summary report
            if self._get_config_value('output', 'create_summary_report', True):
                self._create_summary_report(data, output_dir, timestamp)
                
        except Exception as e:
            logging.error(f"Export failed: {e}")
            self.presenter.present_error(f"Export error: {str(e)}")
    
    def _create_summary_report(self, data: dict, output_dir: str, timestamp: str) -> None:
        """Create human-readable summary report"""
        try:
            summary_filename = os.path.join(output_dir, f"redhat_summary_{timestamp}.txt")
            health_metrics = self.api_client.get_service_health_metrics(data)
            
            with open(summary_filename, 'w', encoding='utf-8') as f:
                f.write("RED HAT STATUS SUMMARY REPORT\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"Page: {health_metrics['page_name']}\n")
                f.write(f"URL: {health_metrics['page_url']}\n")
                f.write(f"Last Update: {health_metrics['last_updated']}\n\n")
                
                f.write(f"Status: {health_metrics['overall_status']}\n")
                f.write(f"Indicator: {health_metrics['status_indicator']}\n\n")
                
                f.write(f"Global Availability: {health_metrics['availability_percentage']:.1f}%\n")
                f.write(f"Total Services: {health_metrics['total_services']}\n")
                f.write(f"Operational: {health_metrics['operational_services']}\n")
                f.write(f"With Issues: {health_metrics['services_with_issues']}\n\n")
                
                f.write(f"Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            
            self.presenter.present_message(f"üìã Summary report created: {summary_filename}")
            
        except Exception as e:
            logging.error(f"Failed to create summary report: {e}")
            self.presenter.present_error(f"Error creating summary report: {str(e)}")
    
    def show_performance_metrics(self) -> None:
        """Display performance metrics"""
        try:
            from redhat_status.core.cache_manager import get_cache_manager
            cache_manager = get_cache_manager()
            cache_info = cache_manager.get_cache_info()
            
            db_stats = None
            if self.db_manager:
                try:
                    db_stats = self.db_manager.get_database_stats()
                except Exception as e:
                    logging.error(f"Failed to get database stats: {e}")

            notif_stats = None
            if self.notification_manager:
                try:
                    notif_stats = self.notification_manager.get_notification_stats()
                except Exception as e:
                    logging.error(f"Failed to get notification stats: {e}")

            self.presenter.present_performance_metrics(self.performance, cache_info, db_stats, notif_stats)
                
        except Exception as e:
            logging.error(f"Performance metrics display failed: {e}")
            self.presenter.present_error(f"Error displaying performance metrics: {e}")


def create_argument_parser() -> argparse.ArgumentParser:
    """Create and configure argument parser"""
    parser = argparse.ArgumentParser(
        description="Red Hat Status Checker - Monitor Red Hat services status",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                    # Interactive mode
  %(prog)s quick              # Quick status only
  %(prog)s simple             # Main services check
  %(prog)s full               # Complete structure
  %(prog)s export             # Export data to files
  %(prog)s all                # Display everything
  %(prog)s quick --quiet      # Minimal output
  %(prog)s export --output ./reports  # Export to specific directory
  %(prog)s --performance      # Show performance metrics
  
Advanced Features:
  %(prog)s --ai-insights       # Show detailed AI analysis
  %(prog)s --health-report     # Generate comprehensive health report
  %(prog)s --anomaly-analysis  # Advanced anomaly detection
  %(prog)s --trends           # Show availability trends
  %(prog)s --slo-dashboard    # View SLO tracking dashboard
  %(prog)s --export-ai-report # Export AI analysis to file
  %(prog)s --filter issues    # Show only services with issues
  %(prog)s --search "registry" # Search for specific services
  %(prog)s --watch 30         # Live monitoring (30s refresh)
  %(prog)s --benchmark        # Performance benchmarking
  %(prog)s --no-cache         # Bypass cache for fresh data
  %(prog)s --enable-exporter  # Run Prometheus exporter
        """
    )
    
    parser.add_argument(
        'mode',
        nargs='?',
        choices=['quick', 'simple', 'full', 'export', 'all'],
        default=None,
        help='Operation mode (if not specified, interactive mode is used)'
    )
    
    parser.add_argument(
        '--output', '-o',
        default='.',
        help='Output directory for exported files (default: current directory)'
    )
    
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Quiet mode - minimal output'
    )
    
    parser.add_argument(
        '--performance',
        action='store_true',
        help='Show performance metrics'
    )
    
    parser.add_argument(
        '--clear-cache',
        action='store_true',
        help='Clear all cached data'
    )
    
    parser.add_argument(
        '--config-check',
        action='store_true',
        help='Validate configuration and display settings'
    )
    
    parser.add_argument(
        '--test-notifications',
        action='store_true',
        help='Test all notification channels'
    )
    
    parser.add_argument(
        '--analytics-summary',
        action='store_true',
        help='Show AI analytics summary (enterprise feature)'
    )
    
    parser.add_argument(
        '--db-maintenance',
        action='store_true',
        help='Perform database maintenance (enterprise feature)'
    )
    
    # === AI Analytics & Insights ===
    parser.add_argument(
        '--ai-insights',
        action='store_true',
        help='Show detailed AI analysis and insights'
    )
    
    parser.add_argument(
        '--anomaly-analysis',
        action='store_true',
        help='Perform advanced anomaly detection analysis'
    )
    
    parser.add_argument(
        '--health-report',
        action='store_true',
        help='Generate comprehensive health analysis report'
    )
    
    parser.add_argument(
        '--insights',
        action='store_true',
        help='Show system insights and patterns'
    )
    
    parser.add_argument(
        '--trends',
        action='store_true',
        help='Show availability trends and predictions'
    )
    
    parser.add_argument(
        '--slo-dashboard',
        action='store_true',
        dest='slo_dashboard',
        help='View SLO tracking and objectives'
    )
    
    # === Export & Reporting ===
    parser.add_argument(
        '--export-ai-report',
        action='store_true',
        help='Generate and export AI analysis report'
    )
    
    parser.add_argument(
        '--export-history',
        action='store_true',
        help='Export historical data to files'
    )
    
    parser.add_argument(
        '--format',
        choices=['json', 'csv', 'txt'],
        default='json',
        help='Output format for exports (default: json)'
    )
    
    # === Service Operations ===
    parser.add_argument(
        '--filter',
        choices=['all', 'issues', 'operational', 'degraded'],
        default='all',
        help='Filter services by status'
    )
    
    parser.add_argument(
        '--search',
        type=str,
        help='Search services by name (case-insensitive)'
    )
    
    parser.add_argument(
        '--concurrent-check',
        action='store_true',
        help='Enable multi-threaded health checks'
    )
    
    # === Monitoring & Live Features ===
    parser.add_argument(
        '--watch',
        type=int,
        metavar='SECONDS',
        help='Live monitoring mode with refresh interval'
    )
    
    parser.add_argument(
        '--notify',
        action='store_true',
        help='Send notifications for current status'
    )
    
    parser.add_argument(
        '--benchmark',
        action='store_true',
        help='Run performance benchmarking tests'
    )
    
    # === Configuration & Debug ===
    parser.add_argument(
        '--no-cache',
        action='store_true',
        help='Bypass cache and force fresh data'
    )
    
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='Set logging level (default: INFO)'
    )
    
    parser.add_argument(
        '--enable-monitoring',
        action='store_true',
        help='Enable continuous monitoring mode'
    )
    
    # --- Exporter Arguments ---
    parser.add_argument(
        '--enable-exporter',
        action='store_true',
        help='Enable the Prometheus exporter to expose metrics on /metrics'
    )

    parser.add_argument(
        '--exporter-port',
        type=int,
        default=8000,
        help='Port for the Prometheus exporter (default: 8000)'
    )

    # --- Web UI Arguments ---
    parser.add_argument(
        '--web',
        action='store_true',
        help='Run the Flask web UI'
    )

    parser.add_argument(
        '--web-port',
        type=int,
        default=5000,
        help='Port for the Web UI (default: 5000)'
    )

    parser.add_argument(
        '--setup',
        action='store_true',
        help='Run configuration setup wizard'
    )
    
    parser.add_argument(
        '--version', '-v',
        action='version',
        version='Red Hat Status Checker v3.1.0 - Modular Edition'
    )
    
    return parser


def main():
    """Main function with improved argument handling"""
    try:
        parser = create_argument_parser()
        args = parser.parse_args()

        # Handle web UI flag, which is a special mode that runs exclusively
        if args.web:
            from redhat_status.web.app import run_web_server
            run_web_server(port=args.web_port)
            return
        
        exporter_module = None
        if args.enable_exporter:
            from redhat_status.exporters import prometheus_exporter as exporter_module
            exporter_module.start_exporter_http_server(port=args.exporter_port)

        app = RedHatStatusChecker(exporter_module=exporter_module)
        presenter = app.presenter

        # Create a dispatch table for special operations
        dispatch_table = {
            'clear_cache': handle_clear_cache,
            'config_check': handle_config_check,
            'test_notifications': handle_test_notifications,
            'analytics_summary': handle_analytics_summary,
            'db_maintenance': handle_db_maintenance,
            'ai_insights': handle_ai_insights,
            'anomaly_analysis': handle_anomaly_analysis,
            'health_report': handle_health_report,
            'insights': handle_insights,
            'trends': handle_trends,
            'slo_dashboard': handle_slo_dashboard,
            'export_ai_report': handle_export_ai_report,
            'export_history': handle_export_history,
            'watch': handle_watch,
            'notify': handle_notify,
            'benchmark': handle_benchmark,
            'setup': handle_setup,
        }

        # Handle special flags that exit immediately
        for arg, handler in dispatch_table.items():
            if getattr(args, arg):
                handler(app, args)
                return

        # Handle pre-run configurations
        if args.no_cache:
            presenter.present_message("üö´ CACHE BYPASS ENABLED")
            app.api_client._bypass_cache = True
        
        if args.log_level:
            level = getattr(logging, args.log_level.upper())
            logging.getLogger().setLevel(level)
            presenter.present_message(f"üîß Log level set to: {args.log_level}")
        
        if args.concurrent_check:
            presenter.present_message("‚ö° ENABLING MULTI-THREADED HEALTH CHECKS")
            app.api_client._concurrent_mode = True

        if args.enable_monitoring:
            presenter.present_message("üìä CONTINUOUS MONITORING ENABLED")
            if app.analytics:
                app.analytics._monitoring_enabled = True

        # Show header unless in quiet mode
        if not args.quiet:
            presenter.present_message("üéØ RED HAT STATUS CHECKER - MODULAR EDITION v3.1.0")
            presenter.present_message("=" * 60)
        
        mode = args.mode
        
        # Handle interactive mode
        if mode is None and not args.quiet and not (args.filter != 'all' or args.search):
            mode = get_interactive_mode(presenter)

        # If no mode is specified (e.g. only --enable-exporter is used),
        # keep the application alive to serve metrics.
        if mode is None and args.enable_exporter:
            presenter.present_message("Exporter is running. No mode selected. Application will idle.")
            presenter.present_message("Perform a check in another terminal to populate metrics, e.g., `python3 redhat_status.py quick`")
            presenter.present_message("Press Ctrl+C to stop.")
            while True:
                time.sleep(1)

        # Default to quick mode if no mode specified
        if mode is None:
            mode = "quick"
        
        # Handle filtering and search, which is a distinct operation
        if args.filter != 'all' or args.search:
            handle_filter_and_search(app, args)
            return
        
        # Execute the requested primary mode
        execute_main_mode(app, mode, args)

    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è  Operation cancelled by user")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Application error: {e}", exc_info=True)
        print(f"\n‚ùå Unexpected error: {str(e)}")
        sys.exit(1)

def execute_main_mode(app, mode, args):
    """Executes the primary operation mode (quick, simple, etc.)."""
    with Timer("Operation", log_result=False) as timer:
        if mode == "quick":
            app.quick_status_check(quiet_mode=args.quiet)
        elif mode == "simple":
            app.quick_status_check(quiet_mode=args.quiet)
            app.simple_check_only()
        elif mode == "full":
            app.quick_status_check(quiet_mode=args.quiet)
            app.simple_check_only()
            app.full_check_with_services()
        elif mode == "export":
            app.export_to_file(args.output)
        elif mode == "all":
            app.quick_status_check(quiet_mode=args.quiet)
            app.simple_check_only()
            app.full_check_with_services()
            app.export_to_file(args.output)

    if args.performance:
        app.show_performance_metrics()

    if not args.quiet:
        app.presenter.present_message(f"\n‚úÖ Operation completed successfully in {timer.duration:.2f}s!")

def get_interactive_mode(presenter):
    """Handles interactive mode selection."""
    presenter.present_message("Available modes:")
    presenter.present_message("  quick    - Global status only")
    presenter.present_message("  simple   - Main services")
    presenter.present_message("  full     - Complete structure")
    presenter.present_message("  export   - Export data")
    presenter.present_message("  all      - Display all")
    print()
    mode = input("Choose a mode (or press Enter for 'quick'): ").lower()
    if not mode:
        mode = "quick"

    if mode not in ['quick', 'simple', 'full', 'export', 'all']:
        presenter.present_error(f"Mode '{mode}' not recognized, using 'quick'")
        mode = "quick"
    return mode

# --- Handler Functions for Dispatch Table ---

def handle_clear_cache(app, args):
    from redhat_status.core.cache_manager import get_cache_manager
    cache_manager = get_cache_manager()
    cleared = cache_manager.clear()
    # Use both print and presenter for compatibility with tests
    message = f"‚úÖ Cache cleared: {cleared} files removed"
    print(message)
    if hasattr(app, 'presenter') and app.presenter:
        app.presenter.present_message(message)

def handle_config_check(app, args):
    config = get_config()
    validation = config.validate()
    
    # Use both print and presenter for compatibility with tests
    header = "üîß CONFIGURATION VALIDATION"
    separator = "=" * 40
    status = f"Status: {'‚úÖ Valid' if validation['valid'] else '‚ùå Invalid'}"
    
    print(header)
    print(separator)
    print(status)
    
    if hasattr(app, 'presenter') and app.presenter:
        app.presenter.present_message(header)
        app.presenter.present_message(separator)
        app.presenter.present_message(status)

    if validation['errors']:
        errors_header = "\nErrors:"
        print(errors_header)
        if hasattr(app, 'presenter') and app.presenter:
            app.presenter.present_message(errors_header)
        for error in validation['errors']:
            error_msg = f"  {error}"
            print(error_msg)
            if hasattr(app, 'presenter') and app.presenter:
                app.presenter.present_error(error_msg)

    if validation['warnings']:
        warnings_header = "\nWarnings:"
        print(warnings_header)
        if hasattr(app, 'presenter') and app.presenter:
            app.presenter.present_message(warnings_header)
        for warning in validation['warnings']:
            warning_msg = f"  ‚ö†Ô∏è  {warning}"
            print(warning_msg)
            if hasattr(app, 'presenter') and app.presenter:
                app.presenter.present_message(warning_msg)

def handle_test_notifications(app, args):
    if not app.notification_manager:
        app.presenter.present_error("Notification system not available (enterprise feature disabled)")
        return

    app.presenter.present_message("üß™ TESTING NOTIFICATION CHANNELS")
    app.presenter.present_message("=" * 40)
    results = app.notification_manager.test_all_channels()

    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)

    for channel, success in results.items():
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        app.presenter.present_message(f"{channel}: {status}")

    app.presenter.present_message("-" * 40)
    app.presenter.present_message(f"üìä Results: {success_count}/{total_count} channels passed")

    if success_count < total_count:
        app.presenter.present_message("üí° Note: Failures may be due to test/invalid credentials in config.json")

def handle_filter_and_search(app, args):
    """Handles the logic for filtering and searching services."""
    app.presenter.present_message(f"üîç FILTERING SERVICES")
    if args.filter != 'all':
        app.presenter.present_message(f"üìã Filter: {args.filter}")
    if args.search:
        app.presenter.present_message(f"üîé Search: '{args.search}'")
    app.presenter.present_message("=" * 40)

    response = app.api_client.fetch_status_data()
    if not response.success:
        app.presenter.present_error(f"Failed to fetch services: {response.error_message}")
        return

    services = response.data.get('components', [])
    filtered_services = []

    for service in services:
        status_match = True
        if args.filter != 'all':
            if args.filter == 'issues' and service.get('status') == 'operational':
                status_match = False
            elif args.filter == 'operational' and service.get('status') != 'operational':
                status_match = False
            elif args.filter == 'degraded' and service.get('status') not in ['degraded_performance', 'partial_outage']:
                status_match = False

        search_match = True
        if args.search:
            if args.search.lower() not in service.get('name', '').lower():
                search_match = False

        if status_match and search_match:
            filtered_services.append(service)

    app.presenter.present_message(f"üìä Found {len(filtered_services)} services matching criteria:")
    for service in filtered_services[:20]:
        status_emoji = "üü¢" if service.get('status') == 'operational' else "üü°" if 'degraded' in service.get('status', '') else "üî¥"
        app.presenter.present_message(f"  {status_emoji} {service.get('name', 'Unknown')}: {service.get('status', 'unknown')}")

    if len(filtered_services) > 20:
        app.presenter.present_message(f"  ... and {len(filtered_services) - 20} more services")

# Add other handlers (handle_analytics_summary, handle_db_maintenance, etc.) here
# for brevity, they are not all shown but would follow the same pattern.
def handle_analytics_summary(app, args):
    if not app.analytics:
        app.presenter.present_error("AI Analytics not available (enterprise feature disabled)")
        return
    app.presenter.present_message("ü§ñ AI ANALYTICS SUMMARY")
    app.presenter.present_message("=" * 40)
    summary = app.analytics.get_analytics_summary()
    if summary:
        app.presenter.present_message(f"üìä Data Quality: {summary.get('data_quality', {}).get('total_metrics', 0)} metrics")
        app.presenter.present_message(f"üîç Anomalies (24h): {sum(summary.get('anomaly_counts', {}).values())}")
        app.presenter.present_message(f"üîÆ Predictions (24h): {sum(summary.get('prediction_counts', {}).values())}")
        app.presenter.present_message(f"üìà Service Health: {len(summary.get('service_health', []))} services monitored")
    else:
        app.presenter.present_error("No analytics data available")

def handle_db_maintenance(app, args):
    if not app.db_manager:
        app.presenter.present_error("Database system not available (enterprise feature disabled)")
        return
    app.presenter.present_message("üîß DATABASE MAINTENANCE")
    app.presenter.present_message("=" * 40)
    app.presenter.present_message("Running cleanup...")
    cleanup_results = app.db_manager.cleanup_old_data()
    for table, count in cleanup_results.items():
        app.presenter.present_message(f"  {table}: {count} records cleaned")

    app.presenter.present_message("\nRunning vacuum...")
    vacuum_success = app.db_manager.vacuum_database()
    app.presenter.present_message(f"  Vacuum: {'‚úÖ Success' if vacuum_success else '‚ùå Failed'}")

    app.presenter.present_message("\nRunning analyze...")
    analyze_success = app.db_manager.analyze_database()
    app.presenter.present_message(f"  Analyze: {'‚úÖ Success' if analyze_success else '‚ùå Failed'}")

def handle_ai_insights(app, args):
    """Show AI-powered insights and analytics"""
    app.presenter.present_message("\nü§ñ AI INSIGHTS & ANALYTICS")
    app.presenter.present_message("=" * 40)
    
    try:
        from redhat_status.analytics.ai_analytics import AIAnalytics
        
        # Get current data for analysis
        response = fetch_status_data()
        if not response.success:
            app.presenter.present_error(f"Failed to fetch data: {response.error_message}")
            return
        
        data = response.data
        ai_analytics = AIAnalytics()
        
        # Get recent anomalies using historical data
        app.presenter.present_message("\nüîç Anomaly Analysis:")
        try:
            # Try to get historical data for anomaly detection
            if hasattr(app, 'db_manager') and app.db_manager.is_enabled():
                historical_data = app.db_manager.get_status_history(limit=50)
                if historical_data:
                    anomalies = ai_analytics.detect_anomalies(historical_data)
                    if isinstance(anomalies, list) and anomalies:
                        for anomaly in anomalies[:5]:  # Show top 5
                            severity_emoji = "üî¥" if anomaly.severity == AlertSeverity.CRITICAL else "üü°" if anomaly.severity == AlertSeverity.WARNING else "üîµ"
                            app.presenter.present_message(f"  {severity_emoji} {anomaly.service_name}: {anomaly.description}")
                    else:
                        app.presenter.present_message("  ‚úÖ No significant anomalies detected")
                else:
                    app.presenter.present_message("  ‚ÑπÔ∏è Insufficient historical data for anomaly detection")
            else:
                app.presenter.present_message("  ‚ö†Ô∏è Database not available for anomaly analysis")
        except Exception as e:
            app.presenter.present_message(f"  ‚ö†Ô∏è Anomaly detection failed: {e}")
        
        # Get current health insights
        app.presenter.present_message("\nüí° Current Health Analysis:")
        try:
            health_metrics = app.api_client.get_service_health_metrics(data)
            
            # Generate health score
            health_score_data = ai_analytics.generate_health_score(data)
            if health_score_data:
                app.presenter.present_message(f"  üìä Health Score: {health_score_data}")
            
            # Provide basic health analysis
            availability = health_metrics.get('availability_percentage', 0)
            if availability >= 99.0:
                app.presenter.present_message("  ‚úÖ Excellent health: All systems operating normally")
            elif availability >= 95.0:
                app.presenter.present_message("  üü° Good health: Minor issues detected")
            else:
                app.presenter.present_message("  üî¥ Health concern: Significant service disruptions")
                
            # Try to generate predictions for main services
            app.presenter.present_message("\nüîÆ Predictive Analysis:")
            try:
                predictions = ai_analytics.generate_predictions("Red Hat", hours_ahead=24)
                if predictions:
                    for prediction in predictions[:2]:  # Show top 2
                        app.presenter.present_message(f"  üìà {prediction.title}: {prediction.description}")
                else:
                    app.presenter.present_message("  ‚ÑπÔ∏è Insufficient data for predictions")
            except Exception as e:
                app.presenter.present_message(f"  ‚ö†Ô∏è Prediction analysis failed: {e}")
                
        except Exception as e:
            app.presenter.present_message(f"  ‚ö†Ô∏è Health analysis failed: {e}")
            
    except Exception as e:
        app.presenter.present_error(f"Error generating AI insights: {e}")

def handle_anomaly_analysis(app, args):
    """Run focused anomaly detection analysis"""
    app.presenter.present_message("\nüîç ANOMALY DETECTION ANALYSIS")
    app.presenter.present_message("=" * 45)
    
    try:
        from redhat_status.analytics.ai_analytics import AIAnalytics
        
        if not hasattr(app, 'db_manager') or not app.db_manager.is_enabled():
            app.presenter.present_message("‚ùå Database not available for anomaly analysis")
            app.presenter.present_message("üí° Run the application with normal modes first to collect data")
            return
        
        ai_analytics = AIAnalytics()
        
        # Get historical data for analysis
        app.presenter.present_message("\nüìä Collecting Historical Data...")
        historical_data = app.db_manager.get_status_history(limit=100)
        
        if not historical_data:
            app.presenter.present_message("  ‚ö†Ô∏è No historical data available")
            app.presenter.present_message("  üí° Run 'quick' or 'simple' mode a few times to collect baseline data")
            return
        
        app.presenter.present_message(f"  ‚úÖ Analyzing {len(historical_data)} data points")
        
        # Perform anomaly detection
        app.presenter.present_message("\nüîç Running Anomaly Detection...")
        try:
            anomalies = ai_analytics.detect_anomalies(historical_data)
            
            if isinstance(anomalies, dict):
                # Handle dictionary response
                anomaly_count = anomalies.get('anomaly_count', 0)
                if anomaly_count > 0:
                    app.presenter.present_message(f"  üö® Found {anomaly_count} anomalies")
                    
                    # Show anomaly details if available
                    if 'anomalies' in anomalies:
                        for i, anomaly in enumerate(anomalies['anomalies'][:5]):
                            app.presenter.present_message(f"  {i+1}. {anomaly}")
                else:
                    app.presenter.present_message("  ‚úÖ No anomalies detected - system appears stable")
                    
                # Show statistical summary if available
                if 'statistics' in anomalies:
                    stats = anomalies['statistics']
                    app.presenter.present_message(f"\nüìà Statistical Summary:")
                    for key, value in stats.items():
                        app.presenter.present_message(f"  ‚Ä¢ {key}: {value}")
                        
            elif isinstance(anomalies, list):
                # Handle list response
                if anomalies:
                    app.presenter.present_message(f"  üö® Found {len(anomalies)} anomalies")
                    for i, anomaly in enumerate(anomalies[:5]):
                        severity_emoji = "üî¥" if hasattr(anomaly, 'severity') and anomaly.severity == AlertSeverity.CRITICAL else "üü°"
                        service_name = getattr(anomaly, 'service_name', 'Unknown')
                        description = getattr(anomaly, 'description', 'No description')
                        app.presenter.present_message(f"  {severity_emoji} {service_name}: {description}")
                else:
                    app.presenter.present_message("  ‚úÖ No anomalies detected - system appears stable")
            else:
                app.presenter.present_message("  ‚ÑπÔ∏è Anomaly analysis completed (no structured results)")
                
        except Exception as e:
            app.presenter.present_message(f"  ‚ùå Anomaly detection failed: {e}")
        
        # Provide recommendations
        app.presenter.present_message("\nüí° Recommendations:")
        app.presenter.present_message("  ‚Ä¢ Continue monitoring for pattern establishment")
        app.presenter.present_message("  ‚Ä¢ Set up alerts for critical anomalies")
        app.presenter.present_message("  ‚Ä¢ Review historical trends weekly")
        
    except Exception as e:
        app.presenter.present_error(f"Error running anomaly analysis: {e}")

def handle_health_report(app, args):
    """Generate comprehensive health report"""
    app.presenter.present_message("\nüè• COMPREHENSIVE HEALTH REPORT")
    app.presenter.present_message("=" * 50)
    
    try:
        # Get current status
        response = fetch_status_data()
        if not response.success:
            app.presenter.present_error(f"Failed to fetch data: {response.error_message}")
            return
        
        data = response.data
        health_metrics = app.api_client.get_service_health_metrics(data)
        
        # Overall Health Score
        app.presenter.present_message(f"\nüìä Overall Health Score: {health_metrics['availability_percentage']:.1f}%")
        
        # Service breakdown
        app.presenter.present_message(f"\nüìà Service Statistics:")
        app.presenter.present_message(f"  ‚Ä¢ Total Services: {health_metrics['total_services']}")
        app.presenter.present_message(f"  ‚Ä¢ Operational: {health_metrics['operational_services']}")
        app.presenter.present_message(f"  ‚Ä¢ With Issues: {health_metrics['services_with_issues']}")
        
        # Performance metrics if available
        if hasattr(app, 'db_manager') and app.db_manager.is_enabled():
            try:
                recent_snapshots = app.db_manager.get_status_history(limit=5)
                if recent_snapshots:
                    app.presenter.present_message(f"\nüìä Recent Status History:")
                    for snapshot in recent_snapshots:
                        timestamp = snapshot.get('timestamp', 'Unknown')
                        availability = snapshot.get('availability_percentage', 0)
                        app.presenter.present_message(f"  ‚Ä¢ {timestamp}: {availability:.1f}%")
            except Exception as e:
                app.presenter.present_message(f"  ‚ö†Ô∏è Historical data unavailable: {e}")
        
        # Current status details
        app.presenter.present_message(f"\nüéØ Current Status:")
        app.presenter.present_message(f"  ‚Ä¢ Page: {health_metrics['page_name']}")
        app.presenter.present_message(f"  ‚Ä¢ Last Updated: {health_metrics['last_updated']}")
        app.presenter.present_message(f"  ‚Ä¢ Status: {health_metrics['overall_status']}")
        
    except Exception as e:
        app.presenter.present_error(f"Error generating health report: {e}")

def handle_insights(app, args):
    app.presenter.present_message("üí° Insights handler not fully implemented in this refactoring.")

def handle_trends(app, args):
    """Show availability trends and historical data"""
    app.presenter.present_message("\nüìà AVAILABILITY TRENDS")
    app.presenter.present_message("=" * 40)
    
    try:
        if not hasattr(app, 'db_manager') or not app.db_manager.is_enabled():
            app.presenter.present_message("‚ùå Database not available for trend analysis")
            return
        
        # Get historical data
        app.presenter.present_message("\nüìä Recent Status History:")
        recent_snapshots = app.db_manager.get_status_history(limit=10)
        
        if not recent_snapshots:
            app.presenter.present_message("  ‚ÑπÔ∏è No historical data available")
            return
        
        # Display trend data
        total_availability = 0
        for i, snapshot in enumerate(recent_snapshots):
            timestamp = snapshot.get('timestamp', 'Unknown')
            availability = snapshot.get('availability_percentage', 0)
            total_services = snapshot.get('total_services', 0)
            operational = snapshot.get('operational_services', 0)
            
            # Format timestamp for display
            try:
                if isinstance(timestamp, str):
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    time_str = dt.strftime('%H:%M:%S')
                else:
                    time_str = str(timestamp)
            except:
                time_str = str(timestamp)
            
            status_emoji = "üü¢" if availability >= 99.0 else "üü°" if availability >= 95.0 else "üî¥"
            app.presenter.present_message(f"  {status_emoji} {time_str}: {availability:.1f}% ({operational}/{total_services})")
            total_availability += availability
        
        # Calculate average
        avg_availability = total_availability / len(recent_snapshots)
        app.presenter.present_message(f"\nüìä Average Availability (24h): {avg_availability:.1f}%")
        
        # Trend analysis
        if len(recent_snapshots) >= 2:
            latest = recent_snapshots[0].get('availability_percentage', 0)
            oldest = recent_snapshots[-1].get('availability_percentage', 0)
            trend = latest - oldest
            
            if abs(trend) < 0.1:
                trend_emoji = "‚û°Ô∏è"
                trend_desc = "Stable"
            elif trend > 0:
                trend_emoji = "üìà"
                trend_desc = f"Improving (+{trend:.1f}%)"
            else:
                trend_emoji = "üìâ"
                trend_desc = f"Declining ({trend:.1f}%)"
            
            app.presenter.present_message(f"üéØ Trend: {trend_emoji} {trend_desc}")
        
    except Exception as e:
        app.presenter.present_error(f"Error analyzing trends: {e}")

def handle_slo_dashboard(app, args):
    app.presenter.present_message("üìä SLO Dashboard handler not fully implemented in this refactoring.")

def handle_export_ai_report(app, args):
    app.presenter.present_message("üìä Export AI Report handler not fully implemented in this refactoring.")

def handle_export_history(app, args):
    app.presenter.present_message("üìÇ Export History handler not fully implemented in this refactoring.")

def handle_watch(app, args):
    app.presenter.present_message(f"üëÅÔ∏è  LIVE MONITORING MODE (refresh every {args.watch}s)")
    app.presenter.present_message("Press Ctrl+C to stop...")
    try:
        while True:
            # In watch mode, we perform a quiet quick check.
            # This will also update the exporter if it's enabled.
            os.system('clear' if os.name == 'posix' else 'cls')
            app.presenter.present_message(f"üîÑ Live Monitor - {datetime.now().strftime('%H:%M:%S')}")
            app.presenter.present_message("=" * 40)
            app.quick_status_check(quiet_mode=True)
            time.sleep(args.watch)
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Monitoring stopped")

def handle_notify(app, args):
    app.presenter.present_message("üì¢ Notify handler not fully implemented in this refactoring.")

def handle_benchmark(app, args):
    """Run performance benchmark tests"""
    app.presenter.present_message("\nüèÅ PERFORMANCE BENCHMARK")
    app.presenter.present_message("=" * 40)
    
    try:
        import time
        
        # Test API response time
        app.presenter.present_message("\nüåê API Response Time Test:")
        
        for i in range(3):
            start_time = time.time()
            response = fetch_status_data()
            duration = time.time() - start_time
            
            if response.success:
                status_emoji = "‚úÖ"
                result = f"Success ({duration:.3f}s)"
            else:
                status_emoji = "‚ùå"
                result = f"Failed ({duration:.3f}s)"
            
            app.presenter.present_message(f"  Test {i+1}: {status_emoji} {result}")
        
        # Test database operations if available
        if hasattr(app, 'db_manager') and app.db_manager.is_enabled():
            app.presenter.present_message("\nüíæ Database Performance Test:")
            
            # Test write operation
            start_time = time.time()
            try:
                test_data = {
                    'page_name': 'Benchmark Test',
                    'overall_status': 'test',
                    'total_services': 0,
                    'operational_services': 0,
                    'availability_percentage': 100.0
                }
                app.db_manager.save_service_snapshot(test_data, [])
                write_time = time.time() - start_time
                app.presenter.present_message(f"  Write Test: ‚úÖ Success ({write_time:.3f}s)")
            except Exception as e:
                write_time = time.time() - start_time
                app.presenter.present_message(f"  Write Test: ‚ùå Failed ({write_time:.3f}s) - {e}")
            
            # Test read operation
            start_time = time.time()
            try:
                snapshots = app.db_manager.get_status_history(limit=5)
                read_time = time.time() - start_time
                app.presenter.present_message(f"  Read Test: ‚úÖ Success ({read_time:.3f}s) - {len(snapshots)} records")
            except Exception as e:
                read_time = time.time() - start_time
                app.presenter.present_message(f"  Read Test: ‚ùå Failed ({read_time:.3f}s) - {e}")
        
        # Test module imports
        app.presenter.present_message("\nüì¶ Module Import Test:")
        modules_to_test = [
            'redhat_status.core.api_client',
            'redhat_status.analytics.ai_analytics',
            'redhat_status.notifications.notification_manager',
            'redhat_status.presentation.presenter'
        ]
        
        for module_name in modules_to_test:
            start_time = time.time()
            try:
                __import__(module_name)
                import_time = time.time() - start_time
                app.presenter.present_message(f"  {module_name}: ‚úÖ Success ({import_time:.3f}s)")
            except Exception as e:
                import_time = time.time() - start_time
                app.presenter.present_message(f"  {module_name}: ‚ùå Failed ({import_time:.3f}s) - {e}")
        
    except Exception as e:
        app.presenter.present_error(f"Error running benchmark: {e}")

def handle_setup(app, args):
    app.presenter.present_message("‚öôÔ∏è Setup handler not fully implemented in this refactoring.")

if __name__ == "__main__":
    main()
